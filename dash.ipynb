{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dash\n",
    "from dash import dcc\n",
    "from dash import html\n",
    "import dash_bootstrap_components as dbc\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from dash.dependencies import Input, Output, State\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import load_model\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get absolute path of repository\n",
    "path_repo = os.path.dirname(os.path.abspath('app'))\n",
    "\n",
    "# Load models\n",
    "path_model_150 = os.path.join(path_repo, 'models', 'MobileNetV3L_Kaggle_p150_e50')\n",
    "path_model_300 = os.path.join(path_repo, 'models', 'MobileNetV3L_Kaggle_p300_e50')\n",
    "# model_150 = tf.keras.models.load_model(path_model_150)\n",
    "model_150 = load_model(path_model_150)\n",
    "#model_300 = load_model(path_model_300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function that preprocess the custom data\n",
    "def load_and_prep_image(filename, img_shape = IMG_HEIGHT):\n",
    "  img = tf.io.read_file(filename) #read image\n",
    "  img_original = mpimg.imread(filename)\n",
    "  img = tf.image.decode_image(img) # decode the image to a tensor\n",
    "  img = tf.image.resize(img, size = [img_shape, img_shape]) # resize the image\n",
    "  return img, img_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_and_plot(model, filename, class_names):\n",
    "  \"\"\"\n",
    "  Imports an image located at filename, makes a prediction on it with\n",
    "  a trained model and plots the image with the predicted class as the title.\n",
    "  \"\"\"\n",
    "  # Import the target image and preprocess it\n",
    "  img, img_original = load_and_prep_image(filename)\n",
    "\n",
    "  # Make a prediction\n",
    "  pred = model.predict(tf.expand_dims(img, axis=0))\n",
    "\n",
    "  # Get the predicted class\n",
    "  if len(pred[0]) > 1: # check for multi-class\n",
    "    pred_class = class_names[pred.argmax()] # if more than one output, take the max\n",
    "  else:\n",
    "    pred_class = class_names[int(tf.round(pred)[0][0])] # if only one output, round\n",
    "\n",
    "  # Plot the image and predicted class\n",
    "  plt.imshow(img_original)\n",
    "  plt.title(f\"Prediction: {pred_class}\")\n",
    "  plt.axis(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['BLACK REDSTART', 'BLACKBIRD', 'COAL TIT', 'COLLARED DOVE', 'COMMON CHAFFINCH', 'COMMON REDSTART', 'EURASIEN BLUE TIT', 'EURASIEN JAY', 'EURASIEN TREE SPARROW', 'EUROPEAN GREENFINCH', 'EUROPEAN JACKDAW', 'EUROPEAN SERIN', 'GARDEN WARBLER', 'GREAT SPOTTED WOODPECKER', 'LONG TAILED TIT', 'ROOK', 'SHORT-TOED TREECREEPER', 'SONG THRUSH', 'SPOTTED FLYCATCHER', 'WHITE WAGTAIL', 'WILLOW WARBLER', 'YELLOWHAMMER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amsel = path_repo + '/images_test-samples/' + 'Amsel.jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# amsel - blackbird\n",
    "pred_and_plot(model_150,amsel, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(path_repo, 'labelmap_europe.txt'), header=None, names=['species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelmap = df.species.tolist()\n",
    "labelmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, label, image):\n",
    "    '''\n",
    "    image: path to image\n",
    "    label: labelmap (as list)\n",
    "    model: the model\n",
    "    '''\n",
    "    if model==model_150:  # or 150x150 MobileNetV3L ?\n",
    "        IMG_SHAPE = 150\n",
    "    elif model==model_300:\n",
    "        IMG_SHAPE = 300\n",
    "\n",
    "    # preprocessing\n",
    "    img = tf.io.read_file(image) #read image\n",
    "    img = tf.image.decode_image(img) # decode the image to a tensor\n",
    "    img = tf.image.resize(img, size = [IMG_SHAPE, IMG_SHAPE]) # resize the image\n",
    "\n",
    "    # prediction\n",
    "    pred = model.predict(tf.expand_dims(img, axis=0))\n",
    "\n",
    "    # get 3 indices with the highest values and sort descending\n",
    "    ind = np.argpartition(pred.flatten(), -3)[-3:]\n",
    "    top3 = pred.flatten()[ind]\n",
    "\n",
    "    # create list of tuples with indices and values\n",
    "    top = []\n",
    "    for idx, val in zip(ind, top3):\n",
    "        top.append((val, idx))\n",
    "\n",
    "    # per default, it will be sorted by first entry of tuples, but ascending\n",
    "    top.sort(reverse=True)\n",
    "    \n",
    "    #\n",
    "    values = [top[i][0]*100 for i in range(3)]\n",
    "    names = [label[top[i][1]] for i in range(3)]\n",
    "    \n",
    "\n",
    "    return values, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_vals, pred_label = predict(model_150, labelmap, amsel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_plot(values, names):\n",
    "    z=[12,24,48] # colors of the viridis colormap\n",
    "    fig = go.Figure(go.Bar(\n",
    "            x=values,\n",
    "            y=names,\n",
    "            orientation='h',\n",
    "            marker=dict(color = z,\n",
    "                        colorscale='viridis')\n",
    "                        )   \n",
    "                    )\n",
    "\n",
    "    # Adding labels\n",
    "    annotations = []\n",
    "    y_s = np.round(values, decimals=2)\n",
    "    \n",
    "    for yd, xd in zip(y_s, names):\n",
    "        # labeling the bar\n",
    "        annotations.append(dict(\n",
    "                            y=xd, x=yd + 5,\n",
    "                            text=str(yd) + '%',\n",
    "                            font=dict(family='Arial', size=16,\n",
    "                                      #color='rgb(50, 171, 96)'\n",
    "                                      ),\n",
    "                            showarrow=False\n",
    "                            ))\n",
    "    fig.update_layout(annotations=annotations)\n",
    "    fig.update_xaxes(visible=False, showticklabels=False)\n",
    "    #fig.show()\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_plot(pred_vals, pred_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ce13fc066535b700db8c25fa6a8da64c2840112eec7bdae2ffdf44f0d0be2040"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
